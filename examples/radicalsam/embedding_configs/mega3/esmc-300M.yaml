# Directory containing the input files to embed.
input_dir: data/radicalsam/mega3

# Directory to save the embeddings.
output_dir: examples/radicalsam/embeddings/mega3/esmc-300M_radicalsam_mega3

# Glob patterns to match the input files.
glob_patterns:
  - "*.fasta"

# Whether to store the token embeddings.
store_token_embeddings: true
token_embedding_buffer_size: 50_000

# Configuration for the encoder.
encoder_config:
  # The encoder name
  name: esmc
  # The model name or path to the pretrained model.
  pretrained_model_name_or_path: esmc_300m
  # Whether to normalize the embeddings
  normalize_pooled_embeddings: true
  # The batch size to use for embedding
  dataloader_batch_size: 8

# Compute settings can be configured by referring to protein_search_evals/parsl.py
# The `name` field specifies what type of system to run on and the subsequent
# arguments are conditional on the name field (e.g., a cluster may have different
# configuration than a workstation).
compute_config:
  # Specify we want the workstation parsl configuration
  name: workstation
  # Identify which GPUs to assign tasks to. It's generally recommended to first check
  # nvidia-smi to see which GPUs are available. The numbers below are analogous to
  # setting CUDA_VISIBLE_DEVICES=5
  available_accelerators: ["5"]
